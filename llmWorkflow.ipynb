{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kdhenderson/msds_colab_notebooks/blob/main/llmWorkflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTqTuztNMVgI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "from openai import OpenAI\n",
        "import csv\n",
        "\n",
        "\n",
        "client = OpenAI(\n",
        "    base_url=\"https://api.groq.com/openai/v1\",\n",
        "    api_key=os.getenv(\"GROQ_API_KEY\"))\n",
        "\n",
        "question = 'explain quantum computing in simple terms'\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "    messages=[{\"role\": \"user\", \"content\": question}])\n",
        "\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "    messages=[{\"role\": \"user\", \"content\": question},\n",
        "              {\"role\": \"assistant\", \"content\": completion.choices[0].message.content},\n",
        "              {\"role\": \"user\", \"content\": 'what did I just say?'}])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def load_tweets():\n",
        "    tweets = []\n",
        "    with open('data.csv', 'r') as file:\n",
        "        csv_reader = csv.DictReader(file)\n",
        "        for row in csv_reader:\n",
        "            tweets.append(row)\n",
        "    return tweets\n",
        "\n",
        "tweets = load_tweets()\n",
        "\n",
        "# Prompt template for keyword extraction\n",
        "keyword_prompt = \"\"\"Given this tweet, assign ONE keyword from the following list that best describes the main theme:\n",
        "- NATURE\n",
        "- FOOD\n",
        "- LEARNING\n",
        "- FAMILY\n",
        "- ACHIEVEMENT\n",
        "- CREATIVITY\n",
        "\n",
        "Tweet: {tweet}\n",
        "\n",
        "Return only the keyword, nothing else.\"\"\"\n",
        "\n",
        "# Process each tweet\n",
        "for tweet in tweets[:1]:\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"llama-3.3-70b-versatile\",\n",
        "        messages=[{\"role\": \"user\", \"content\": keyword_prompt.format(tweet=tweet['tweet'])}]\n",
        "    )\n",
        "    keyword = completion.choices[0].message.content.strip()\n",
        "    tweet['keyword'] = keyword\n",
        "\n",
        "print(tweet)\n",
        "\n",
        "\n",
        "\n",
        "print(completion.choices[0].message.content)\n",
        "\n",
        "# Example of an agentic workflow: Essay Writer and Reviewer\n",
        "\n",
        "# First agent: Essay Writer\n",
        "essay_prompt = \"\"\"Write a one-paragraph essay about the importance of space exploration.\n",
        "Make it engaging and informative, suitable for a general audience.\"\"\"\n",
        "\n",
        "essay_completion = client.chat.completions.create(\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "    messages=[{\"role\": \"user\", \"content\": essay_prompt}]\n",
        ")\n",
        "\n",
        "essay = essay_completion.choices[0].message.content\n",
        "print(\"Essay Writer Agent's Output:\")\n",
        "print(\"-\" * 50)\n",
        "print(essay)\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Second agent: Essay Reviewer\n",
        "review_prompt = f\"\"\"You are a professional essay reviewer. Review the following one-paragraph essay.\n",
        "Focus on:\n",
        "1. Clarity of main argument\n",
        "2. Use of evidence\n",
        "3. Writing style\n",
        "4. Areas for improvement\n",
        "\n",
        "Essay to review:\n",
        "{essay}\n",
        "\n",
        "Provide a structured review with specific examples.\"\"\"\n",
        "\n",
        "review_completion = client.chat.completions.create(\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "    messages=[{\"role\": \"user\", \"content\": review_prompt}]\n",
        ")\n",
        "\n",
        "print(\"\\nEssay Reviewer Agent's Output:\")\n",
        "print(\"-\" * 50)\n",
        "review = review_completion.choices[0].message.content\n",
        "print(review)\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Third agent: Essay Reviser\n",
        "revision_prompt = f\"\"\"You are an expert essay writer. You will receive an original essay and a reviewer's feedback.\n",
        "Your task is to rewrite the essay, carefully addressing all the reviewer's points while maintaining the original topic and scope.\n",
        "\n",
        "Original essay:\n",
        "{essay}\n",
        "\n",
        "Reviewer's feedback:\n",
        "{review}\n",
        "\n",
        "Please rewrite the essay, incorporating the reviewer's suggestions. Keep it to one paragraph.\"\"\"\n",
        "\n",
        "revision_completion = client.chat.completions.create(\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "    messages=[{\"role\": \"user\", \"content\": revision_prompt}]\n",
        ")\n",
        "print(\"\\nEssay Reviser Agent's Output (Final Version):\")\n",
        "print(\"-\" * 50)\n",
        "print(revision_completion.choices[0].message.content)\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Display the full workflow summary\n",
        "# Fourth agent: 8th Grade Style Adapter\n",
        "revised_essay = revision_completion.choices[0].message.content\n",
        "\n",
        "eighth_grade_prompt = f\"\"\"You're a cool 8th grader who's really into space! Rewrite this essay in your voice.\n",
        "Make it sound like you're explaining it to your friends at lunch, but keep the main points.\n",
        "Use some casual language, maybe a few \"like\" and \"you know,\" but keep it clear and interesting.\n",
        "Don't make it too childish - you're 13-14 years old and smart, just more casual and relatable.\n",
        "\n",
        "Essay to rewrite:\n",
        "{revised_essay}\n",
        "\n",
        "Remember:\n",
        "- Use casual but not silly language\n",
        "- Keep the main facts and ideas\n",
        "- Add some enthusiasm (but not too many exclamation points!)\n",
        "- Maybe mention how this relates to stuff you've seen in movies or games\n",
        "- Keep it to one paragraph\"\"\"\n",
        "\n",
        "eighth_grade_completion = client.chat.completions.create(\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "    messages=[{\"role\": \"user\", \"content\": eighth_grade_prompt}]\n",
        ")\n",
        "\n",
        "print(\"\\nFinal 8th Grade Version:\")\n",
        "print(\"-\" * 50)\n",
        "print(eighth_grade_completion.choices[0].message.content)\n",
        "print(\"-\" * 50)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# New Workflow: Iterative Research and Edit with Decider\n",
        "print(\"\\n=== Iterative Research-Edit-Decide Workflow ===\\n\")\n",
        "\n",
        "research_topic = \"The impact of social media on teenage mental health\"\n",
        "iteration = 1\n",
        "current_content = \"\"\n",
        "\n",
        "def research_agent(topic, current_content):\n",
        "    research_prompt = f\"\"\"You are a thorough researcher. Given the topic and current content (if any),\n",
        "provide new insights or expand the research. If there's existing content, build upon it rather than starting fresh.\n",
        "\n",
        "Topic: {topic}\n",
        "Current Content: {current_content if current_content else 'No content yet - initial research needed'}\n",
        "\n",
        "Provide 2-3 paragraphs of well-researched information, including:\n",
        "- Recent statistics or studies\n",
        "- Expert opinions\n",
        "- Real-world examples\n",
        "- Areas that need more exploration\"\"\"\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"llama-3.3-70b-versatile\",\n",
        "        messages=[{\"role\": \"user\", \"content\": research_prompt}]\n",
        "    )\n",
        "    return completion.choices[0].message.content\n",
        "\n",
        "def editor_agent(research_content):\n",
        "    editor_prompt = f\"\"\"You are an expert editor. Review and improve the following research content.\n",
        "Focus on:\n",
        "- Clarity and flow\n",
        "- Logical organization\n",
        "- Compelling narrative\n",
        "- Identifying gaps or inconsistencies\n",
        "\n",
        "Content to edit:\n",
        "{research_content}\n",
        "\n",
        "Provide an improved version that maintains accuracy while enhancing readability.\"\"\"\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"llama-3.3-70b-versatile\",\n",
        "        messages=[{\"role\": \"user\", \"content\": editor_prompt}]\n",
        "    )\n",
        "    return completion.choices[0].message.content\n",
        "\n",
        "def decider_agent(current_version, iteration):\n",
        "    decider_prompt = f\"\"\"You are the final decision maker. Evaluate this content and decide if it's ready for publication.\n",
        "Consider:\n",
        "1. Comprehensiveness of the research\n",
        "2. Clarity of presentation\n",
        "3. Logical flow\n",
        "4. Whether key questions are answered\n",
        "5. Overall impact\n",
        "\n",
        "Current Version (Iteration {iteration}):\n",
        "{current_version}\n",
        "\n",
        "Respond with:\n",
        "1. A brief evaluation of the current version\n",
        "2. Either \"DONE\" if it's ready for publication, or \"CONTINUE\" with specific aspects that need more work.\"\"\"\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"llama-3.3-70b-versatile\",\n",
        "        messages=[{\"role\": \"user\", \"content\": decider_prompt}]\n",
        "    )\n",
        "    return completion.choices[0].message.content\n",
        "\n",
        "# Run the iterative workflow\n",
        "while True:\n",
        "    print(f\"\\nIteration {iteration}\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    # Research phase\n",
        "    print(\"\\nResearcher Agent Working...\")\n",
        "    research_content = research_agent(research_topic, current_content)\n",
        "    print(\"Research Output:\")\n",
        "    print(research_content)\n",
        "\n",
        "    # Editor phase\n",
        "    print(\"\\nEditor Agent Working...\")\n",
        "    edited_content = editor_agent(research_content)\n",
        "    print(\"Edited Version:\")\n",
        "    print(edited_content)\n",
        "\n",
        "    # Decider phase\n",
        "    print(\"\\nDecider Agent Evaluating...\")\n",
        "    decision = decider_agent(edited_content, iteration)\n",
        "    print(\"Decider's Evaluation:\")\n",
        "    print(decision)\n",
        "\n",
        "    # Update current content for next iteration\n",
        "    current_content = edited_content\n",
        "\n",
        "    # Check if we're done\n",
        "    if \"DONE\" in decision.upper():\n",
        "        print(f\"\\nProcess completed in {iteration} iterations!\")\n",
        "        print(\"\\nFinal Version:\")\n",
        "        print(\"-\" * 30)\n",
        "        print(current_content)\n",
        "        break\n",
        "\n",
        "    iteration += 1\n",
        "    if iteration > 5:  # Safety limit\n",
        "        print(\"\\nReached maximum iterations. Final version:\")\n",
        "        print(current_content)\n",
        "        break\n",
        "\n",
        "print(\"-\" * 50)\n"
      ]
    }
  ]
}